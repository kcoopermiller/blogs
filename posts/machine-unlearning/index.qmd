---
title: "NeurIPS 2023 - Machine Unlearning Submission"
author: "Cooper Miller"
date: "2023-11-28"
categories: [ai/ml]
image: "unlearning.png"
title-block-banner: "#f7f7f7"
title-block-banner-color: "black"
title-block-style: default
navbar: false
theme: ../../custom.scss
format: 
  html:
    code-fold: true
    css: ../../style.css
jupyter: python3
toc: true
# notebook-view: 
# - notebook: unlearning.ipynb
#   title: "Unlearning"
#   url: https://www.kaggle.com/code/kcoopermiller/unlearning
---
<a 
style="font-size: 13px; color: #4e5154" className="home" href="https://kcoopermiller.github.io">RETURN HOME</a>

<!-- Machine unlearning refers to the process by which a machine learning model is able to effectively 'unlearn' or remove specific data from its training set. 

In this experiment, we utilized sparse autoencoders to 
This approach is derived from Anthropic's "Towards Monosemanticity: Decomposing Language Models With Dictionary Learning", applying their methods to generate interpretable features of a neural network to the field of machine unlearning. -->



```{dot}
graph percolation {
    node [shape=circle];
    // Define nodes
    A; B; C; D; E; F; G; H; I;
    // Define edges
    A -- B; A -- D; B -- C; B -- E; C -- F;
    D -- E; D -- G; E -- F; E -- H; F -- I;
    G -- H; H -- I;
    // You can add more nodes and edges to expand the graph
}
```


# Setup

## Model
<!-- Transformer for language
Resnet for Image classification? -->

## Data

# Methodology

# Results

## MIA
## Competition Metric
## Autoencoder Failure

```{python}
import matplotlib.pyplot as plt
import numpy as np

fig = plt.figure()
x = np.arange(10)
y = 2.5 * np.sin(x / 20 * np.pi)
yerr = np.linspace(0.05, 0.2, 10)

plt.errorbar(x, y + 3, yerr=yerr, label='both limits (default)')
plt.errorbar(x, y + 2, yerr=yerr, uplims=True, label='uplims=True')
plt.errorbar(x, y + 1, yerr=yerr, uplims=True, lolims=True,
             label='uplims=True, lolims=True')

upperlimits = [True, False] * 5
lowerlimits = [False, True] * 5
plt.errorbar(x, y, yerr=yerr, uplims=upperlimits, lolims=lowerlimits,
             label='subsets of uplims and lolims')

plt.legend(loc='lower right')
plt.show(fig)
```


# Conclusion
## Motivation
<!-- While it may seem extraneous to turn 
Machine unlearning is 
While techniques such as MIA, ____, or the one proposed in this competition are ways to convice researchers of the efficacy of the unlearning algorithm, it may not be enough to convince those who don't understand the esoteric nature of neural netwoks. Obvious evidence will be a necessity when trying to convince the layman that their data is no longer a part of the network. -->