[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nNov 28, 2023\n\n\nNeurIPS 2023 - Machine Unlearning Submission\n\n\nCooper Miller\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/machine-unlearning/index.html",
    "href": "posts/machine-unlearning/index.html",
    "title": "NeurIPS 2023 - Machine Unlearning Submission",
    "section": "",
    "text": "RETURN HOME\nMachine unlearning refers to the process by which a machine learning model is able to effectively ‘unlearn’ or remove specific data from its training set.\nIn this experiment, we utilized sparse autoencoders to This approach is derived from Anthropic’s “Towards Monosemanticity: Decomposing Language Models With Dictionary Learning”, applying their methods to generate interpretable features of a neural network to the field of machine unlearning.\npercolation\n\n  \n\nA\n\n A   \n\nB\n\n B   \n\nA–B\n\n   \n\nD\n\n D   \n\nA–D\n\n   \n\nC\n\n C   \n\nB–C\n\n   \n\nE\n\n E   \n\nB–E\n\n   \n\nF\n\n F   \n\nC–F\n\n   \n\nD–E\n\n   \n\nG\n\n G   \n\nD–G\n\n   \n\nE–F\n\n   \n\nH\n\n H   \n\nE–H\n\n   \n\nI\n\n I   \n\nF–I\n\n   \n\nG–H\n\n   \n\nH–I"
  },
  {
    "objectID": "posts/machine-unlearning/index.html#model",
    "href": "posts/machine-unlearning/index.html#model",
    "title": "NeurIPS 2023 - Machine Unlearning Submission",
    "section": "Model",
    "text": "Model\nTransformer for language Resnet for Image classification?"
  },
  {
    "objectID": "posts/machine-unlearning/index.html#data",
    "href": "posts/machine-unlearning/index.html#data",
    "title": "NeurIPS 2023 - Machine Unlearning Submission",
    "section": "Data",
    "text": "Data"
  },
  {
    "objectID": "posts/machine-unlearning/index.html#methodology",
    "href": "posts/machine-unlearning/index.html#methodology",
    "title": "NeurIPS 2023 - Machine Unlearning Submission",
    "section": "Methodology",
    "text": "Methodology"
  },
  {
    "objectID": "posts/machine-unlearning/index.html#mia",
    "href": "posts/machine-unlearning/index.html#mia",
    "title": "NeurIPS 2023 - Machine Unlearning Submission",
    "section": "MIA",
    "text": "MIA"
  },
  {
    "objectID": "posts/machine-unlearning/index.html#competition-metric",
    "href": "posts/machine-unlearning/index.html#competition-metric",
    "title": "NeurIPS 2023 - Machine Unlearning Submission",
    "section": "Competition Metric",
    "text": "Competition Metric"
  },
  {
    "objectID": "posts/machine-unlearning/index.html#autoencoder-failure",
    "href": "posts/machine-unlearning/index.html#autoencoder-failure",
    "title": "NeurIPS 2023 - Machine Unlearning Submission",
    "section": "Autoencoder Failure",
    "text": "Autoencoder Failure\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfig = plt.figure()\nx = np.arange(10)\ny = 2.5 * np.sin(x / 20 * np.pi)\nyerr = np.linspace(0.05, 0.2, 10)\n\nplt.errorbar(x, y + 3, yerr=yerr, label='both limits (default)')\nplt.errorbar(x, y + 2, yerr=yerr, uplims=True, label='uplims=True')\nplt.errorbar(x, y + 1, yerr=yerr, uplims=True, lolims=True,\n             label='uplims=True, lolims=True')\n\nupperlimits = [True, False] * 5\nlowerlimits = [False, True] * 5\nplt.errorbar(x, y, yerr=yerr, uplims=upperlimits, lolims=lowerlimits,\n             label='subsets of uplims and lolims')\n\nplt.legend(loc='lower right')\nplt.show(fig)"
  },
  {
    "objectID": "posts/machine-unlearning/index.html#exigence",
    "href": "posts/machine-unlearning/index.html#exigence",
    "title": "NeurIPS 2023 - Machine Unlearning Submission",
    "section": "Exigence",
    "text": "Exigence\nWhile it may seem extraneous to turn Machine unlearning is While techniques such as MIA, ____, or the one proposed in this competition are ways to convice researchers of the efficacy of the unlearning algorithm, it may not be enough to convince those who don’t understand the esoteric nature of neural netwoks. Obvious evidence will be a necessity when trying to convince the layman that their data is no longer a part of the network."
  }
]